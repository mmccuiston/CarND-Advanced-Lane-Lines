{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is where we calibrate our camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load our chessboard images and use OpenCV2 to find the location of the corners on the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "shape = None\n",
    "chessboard_corner_images = []\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    shape = gray.shape[::-1]\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        chessboard_corner_images.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We draw lines between the corners and display them just to verify that the correct corners were detected. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = [0,2,5,7]\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "for plot_num, i in enumerate(test_images):\n",
    "    plt.subplot(2,2,(plot_num + 1))\n",
    "    plt.imshow(chessboard_corner_images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we calculate the camera distortion matrix and the calibration matrix.  We use the OpenCV2 calibrateCamera function to do do this.  This function takes the locations of the previously detected corners on the chessboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, shape, None, None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we view some undistorted images using the previously calculated matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.imread(images[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = cv2.undistort(cv2.imread(images[3]), mtx, dist, None, mtx)\n",
    "plt.imshow(dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we view an undistorted image with straight lane lines.  We manually select 4 points to use for the perspective transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = glob.glob('./test_images/*.jpg')\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "img = plt.imread(test_images[6])\n",
    "undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "plt.imshow(undist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the image above we choose the following points and calculate the perspective transform matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_points = np.float32([[210,725],[590,450],[685,450],[1110,725]])\n",
    "dest_points = np.float32([[210,725],[210,0],[1110,0],[1110,725]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(orig_points, dest_points)\n",
    "Minv = cv2.getPerspectiveTransform(dest_points, orig_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we view the image after the perspective transform is applied to verify that the lines are vertical and parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(test_images[6])\n",
    "undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "warped = cv2.warpPerspective(undist, M, (img.shape[1],img.shape[0]))\n",
    "plt.imshow(warped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lane detection pipeline below does the following.\n",
    "* Undistort the image using the previously calculated matrices from the calibration steps\n",
    "* Apply thresholding to find the lane lines.  I combine two thresholding methods (one for white and yellow) that threshold on HLS values.\n",
    "* Apply a perspective transform to create a top-down view of the lanes\n",
    "* Fit a order 2 polynomial to both the left and right lane line\n",
    "* Create a transparent overlay for the lane using the polynomials as sides to a polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def undistort(img, cameraMatrix, distCoeff):\n",
    "    return cv2.undistort(img, cameraMatrix, distCoeff, None, cameraMatrix)\n",
    "\n",
    "def threshold_white(img):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    H = hls[:,:,0]\n",
    "    L = hls[:,:,1]\n",
    "    S = hls[:,:,2]\n",
    "    h_thresh = (0, 255)\n",
    "    s_thresh = (0, 255)\n",
    "    l_thresh = (200, 255)\n",
    "    binary = np.zeros_like(S)\n",
    "    binary[(L > l_thresh[0]) & (L <= l_thresh[1])] = 1\n",
    "    return binary\n",
    "\n",
    "def threshold_yellow(img):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    H = hls[:,:,0]\n",
    "    L = hls[:,:,1]\n",
    "    S = hls[:,:,2]\n",
    "    s_thresh = (100, 255)\n",
    "    l_thresh = (100, 255)\n",
    "    binary = np.zeros_like(S)\n",
    "    binary[(S > s_thresh[0]) & (S <= s_thresh[1]) & (L > l_thresh[0]) & (L <= l_thresh[1])] = 1\n",
    "    return binary\n",
    "\n",
    "def threshold(img):\n",
    "    yellow = threshold_yellow(img)\n",
    "    white = threshold_white(img)\n",
    "    return np.clip(white + yellow, 0, 1)\n",
    "\n",
    "def perspective_transform(img, M):\n",
    "    return cv2.warpPerspective(img, M, (img.shape[1],img.shape[0]))\n",
    "\n",
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "def fit_poly_to_lanes(img):\n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(img[img.shape[0]/2:,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((img, img, img))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(img.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = img.shape[0] - (window+1)*window_height\n",
    "        win_y_high = img.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    \n",
    "    left_cr = calculate_curvature(leftx, lefty, img.shape[0])\n",
    "    right_cr = calculate_curvature(rightx, righty, img.shape[0])\n",
    "    \n",
    "\n",
    "    vehicle_center_pixel = calculate_center_offset_pixel(left_fit,right_fit,img.shape[1]/2)\n",
    "    pixel_offset = img.shape[1]/2 - vehicle_center_pixel\n",
    "    offset_in_m = pixel_offset * xm_per_pix\n",
    "    \n",
    "    return(left_fit,right_fit, (left_cr + right_cr) / 2.0, offset_in_m)\n",
    "\n",
    "\n",
    "def calculate_center_offset_pixel(left_fit,right_fit,y_eval):\n",
    "    left = left_fit[0] * y_eval ** 2 + left_fit[1] * y_eval + left_fit[2]\n",
    "    right = right_fit[0] * y_eval ** 2 + right_fit[1] * y_eval + right_fit[2]\n",
    "    return (left + right) / 2\n",
    "    \n",
    "\n",
    "def calculate_curvature(x,y,y_eval):    \n",
    "    fit_cr = np.polyfit(y*ym_per_pix, x*xm_per_pix, 2)\n",
    "    \n",
    "    curverad = ((1 + (2*fit_cr[0]*y_eval*ym_per_pix + fit_cr[1])**2)**1.5) / np.absolute(2*fit_cr[0])\n",
    "    \n",
    "    return curverad\n",
    "    \n",
    "\n",
    "def lane_overlay(img, Minv,left_fit,right_fit,curvature,offset):\n",
    "    ploty = np.linspace(0, img.shape[0]-1, num=img.shape[0])\n",
    "    \n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Create an image to draw the lines on\n",
    "    color_warp = np.zeros_like(img).astype(np.uint8)\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0])) \n",
    "\n",
    "    # Combine the result with the original image\n",
    "    \n",
    "    \n",
    "    overlay = cv2.addWeighted(img, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    text1 = cv2.putText(overlay,\"center offset: {:10.4f} m\".format(offset),(10,100), font, 2,(255,255,255),2,cv2.LINE_AA)\n",
    "    text2 = cv2.putText(text1,\"turn radius: {:10.4f} m\".format(curvature),(10,200), font, 2,(255,255,255),2,cv2.LINE_AA)\n",
    "    return text2\n",
    "\n",
    "\n",
    "def pipeline(img, cameraMatrix, distCoeff, M, radii=[], offsets=[]):\n",
    "    undist = undistort( img, cameraMatrix, distCoeff )\n",
    "    thresholded = threshold(undist)\n",
    "    persp = perspective_transform(thresholded, M)\n",
    "    (left_fit,right_fit, curvature, offset) = fit_poly_to_lanes(persp)\n",
    "    radii.append(curvature)\n",
    "    offsets.append(offset)\n",
    "    overlay = lane_overlay(undist, Minv, left_fit, right_fit,curvature,offset)    \n",
    "    return overlay\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a transparent overlay for the lane to verify that our lane detection algorithm works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "test_images = glob.glob('./test_images/*.jpg')\n",
    "straight_lane_lines = test_images[6]\n",
    "img = plt.imread(straight_lane_lines)\n",
    "lanes = pipeline(img, mtx, dist, M)\n",
    "plt.imshow(lanes, cmap=\"gray\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we apply the transparent overlay to every frame in a video recording from the vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radii = []\n",
    "offsets = []\n",
    "\n",
    "def calibrated_pipeline(image):\n",
    "    return pipeline(image,mtx,dist,M,radii,offsets)\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "video_output=\"project_video_output.mp4\"\n",
    "clip = clip1.fl_image(calibrated_pipeline)\n",
    "%time clip.write_videofile(video_output, audio=False)\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"./{0}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_output))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
